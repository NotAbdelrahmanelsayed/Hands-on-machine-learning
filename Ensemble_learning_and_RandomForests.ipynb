{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ensemble_learning_and_RandomForests",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOEQyR5jj8Aj0wMWbWqrTvI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NotAbdelrahmanelsayed/Hands-on-machine-learning/blob/main/Ensemble_learning_and_RandomForests.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GOevwdpVnpao"
      },
      "outputs": [],
      "source": [
        "# Python ≥3.5 is required\n",
        "import sys\n",
        "assert sys.version_info >= (3, 5)\n",
        "\n",
        "# Scikit-Learn ≥0.20 is required\n",
        "import sklearn\n",
        "assert sklearn.__version__ >= \"0.20\"\n",
        "\n",
        "# Common imports\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# to make this notebook's output stable across runs\n",
        "np.random.seed(42)\n",
        "\n",
        "# To plot pretty figures\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)\n",
        "\n",
        "# Where to save the figures\n",
        "PROJECT_ROOT_DIR = \".\"\n",
        "CHAPTER_ID = \"ensembles\"\n",
        "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
        "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
        "\n",
        "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
        "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
        "    print(\"Saving figure\", fig_id)\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format=fig_extension, dpi=resolution)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**how ensemble learning works !**"
      ],
      "metadata": {
        "id": "f8TCltKcn4_E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import the moons data first\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import make_moons\n",
        "\n",
        "X, y = make_moons(n_samples=500, noise=0.30, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
      ],
      "metadata": {
        "id": "omE50f8npb8F"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "log_clf = LogisticRegression()\n",
        "svm_clf = SVC()\n",
        "rnd_clf = RandomForestClassifier()\n",
        "\n",
        "voting_clf = VotingClassifier(\n",
        "    estimators = [('lr', log_clf), ('svc', svm_clf), ('rf', rnd_clf)],\n",
        ")"
      ],
      "metadata": {
        "id": "LK1XFFKDn2H_"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**let's look at the accuarecy**"
      ],
      "metadata": {
        "id": "J0CyPzddo6Fc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "for clf in (log_clf, svm_clf, rnd_clf, voting_clf):\n",
        "  clf.fit(X_train, y_train)\n",
        "  y_pred = clf.predict(X_test)\n",
        "  print(clf.__class__.__name__, accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kViANjxMo4Kb",
        "outputId": "dde46e9b-ee49-43c6-cf5a-db2d3a953df1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression 0.864\n",
            "SVC 0.896\n",
            "RandomForestClassifier 0.888\n",
            "VotingClassifier 0.904\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The voting classifier is slightly better than the best classifier**"
      ],
      "metadata": {
        "id": "6tgyPOMzplMb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random forest"
      ],
      "metadata": {
        "id": "QrEqmNTlwCQt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rnd_clf = RandomForestClassifier(n_estimators=500, max_leaf_nodes=6, n_jobs=-1)\n",
        "rnd_clf.fit(X_train, y_train)\n",
        "y_pred = rnd_clf.predict(X_test)\n",
        "accuracy_score(y_test, y_pred)"
      ],
      "metadata": {
        "id": "BYT86AGIpkeZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c66afe64-3598-413e-a6d5-89c90e3bbe77"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.92"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#AdaBoostClassifier \n",
        "**is a classifier try many random forset algorithms and choose the best i.e 100 algorithm and choose the best one or stop when he found the local optimum algorith let's take a look** "
      ],
      "metadata": {
        "id": "n2w0WXII1Rnk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "ada_clf = AdaBoostClassifier(\n",
        "    DecisionTreeClassifier(max_depth=1), n_estimators = 300, \n",
        "    learning_rate = 0.5\n",
        ")\n",
        "ada_clf.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "ada_clf.score(X_test, y_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ucNttRao11hw",
        "outputId": "f9729ca6-0945-4f59-dbbf-b8679d03f99a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.896"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Gradient Boosting**\n",
        "\n",
        "\n",
        "working for classification and regression just like adaboost\n",
        "\n",
        "\n",
        "Let create a simple quadratic dataset:\n",
        "\n",
        "}"
      ],
      "metadata": {
        "id": "KBoUIrKa1Rgq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "X = np.random.rand(100, 1) - 0.5\n",
        "y = 3*X[:, 0]**2 + 0.05 * np.random.randn(100)"
      ],
      "metadata": {
        "id": "q4P12xUAHi5Z"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "tree_reg = DecisionTreeRegressor(max_depth=2) # max_depth is the maximum leaves of the tree if none it maybe ovefit the data\n",
        "tree_reg.fit(X, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HgFAnFvnwV2I",
        "outputId": "4b4210d8-0212-4756-8d72-937d1519389b"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeRegressor(max_depth=2)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y2 = y - tree_reg.predict(X)\n",
        "tree_reg1 = DecisionTreeRegressor(max_depth=2)\n",
        "tree_reg1.fit(X,y2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9YMeHP-Ft8R",
        "outputId": "f318894b-ce4f-4713-d945-79aa95a4f31b"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeRegressor(max_depth=2)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y3 = y2 - tree_reg1.predict(X)\n",
        "tree_reg2 = DecisionTreeRegressor(max_depth=2)\n",
        "tree_reg2.fit(X, y3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqRGolLPGXVH",
        "outputId": "3a8d4efe-164a-4f71-c1d2-b61c2a379f1f"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeRegressor(max_depth=2)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_new = np.array([[0.8]])\n",
        "y_pred = sum(tree.predict(X_new) for tree in (tree_reg1, tree_reg2, tree_reg))\n"
      ],
      "metadata": {
        "id": "9qwzQjEHG3xw"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNP-aTcfHlDs",
        "outputId": "adc87982-9800-4f23-b5ef-119080b468dc"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.75026781])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**every single tree are trained of the residuals from previous tree and so on till we get the best predections**\n"
      ],
      "metadata": {
        "id": "A4EWm8YgH6QA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**we can use early stopping while find the iptimal number of trees , using GBRT**"
      ],
      "metadata": {
        "id": "dHXHa661JVW9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y)\n",
        "\n",
        "gbrt = GradientBoostingRegressor(max_depth=2, n_estimators=120) # (n_estimators)try to find the local optimal number of trees in 120 try\n",
        "\n",
        "gbrt.fit(X,y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PaMBdTZtHtMS",
        "outputId": "1962393b-eb33-4709-9e15-9c7d0aea85c2"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GradientBoostingRegressor(max_depth=2, n_estimators=120)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "errors = [mean_squared_error(y_val, y_pred)\n",
        "          for y_pred in gbrt.staged_predict(X_val)]\n",
        "best_n_estimators = np.argmin(errors) + 1\n",
        "\n",
        "gbrt_best = GradientBoostingRegressor(max_depth=2, n_estimators=best_n_estimators)\n",
        "gbrt_best.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJWFw9xTJrsj",
        "outputId": "a237e2f8-938e-4856-fcaa-742624ccdbb6"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GradientBoostingRegressor(max_depth=2, n_estimators=120)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    }
  ]
}